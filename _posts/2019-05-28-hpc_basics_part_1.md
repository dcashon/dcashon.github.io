---
layout: post
title: "HPC Basics: Vital Commands, Editors, and Data Transfer"
comments: true
description: "HPC Basics Part 1"
keywords: "dummy content"
---

Public access to high performance computing resources has now been commoditized thanks to cloud providers such as Amazon Web Services,
Google Cloud Platform, and Microsoft Azure. In addition, many academic departments are starting to make use of HPC resources for simulation, machine learning, and other projects. Working with these resources has a bit of a learning curve. Here I hope to share the tools I have found most useful when working with remote HPC resources. This is mostly tailored to UW Hyak, but many things should be broadly applicable.

## Motivation
1. Access to more compute: as data grows, so does the need for more powerful hardware. A typical consumer laptop may have around 4 cores and 16GB of memory. Hyak nodes, for example, have 28 cores and over 100GB of memory. Cloud providers all offer the ability to configure hardware for compute needs. This greatly expands the domain of feasible tasks. 

2. Adaptability: the hardware landscape is constantly changing. Using cloud resources such as AWS decouples you from having to keep up with this change. Rather than spend thousands keeping your local hardware up to date (e.g. GPUs), you can spin up an instance remotely with the hardware that you need, depending on the provider to keep up with the latest changes. This also ensures that you

3. 

## Vital Commands


